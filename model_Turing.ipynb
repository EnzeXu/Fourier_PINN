{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyNANGDpEJoHquLAxxPtN9iF"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install torchdiffeq"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psOjA8vF3qR_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1665907841199,
     "user_tz": 240,
     "elapsed": 5780,
     "user": {
      "displayName": "Enze Xu",
      "userId": "00384414745694091798"
     }
    },
    "outputId": "6712a6b3-4178-4d3e-9fbd-55c86e417f6a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq) (1.7.3)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq) (1.12.1+cu113)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq) (4.1.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import torchdiffeq\n",
    "import sys\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim, autograd\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "main_path = \"/content/drive/My Drive/Workspace/Fourier_PINN/\" # ENZE marked: you need to change your main_path if it's not here\n",
    "sys.path.append(main_path)\n",
    "\n",
    "from utils import draw_two_dimension, draw_three_dimension, MultiSubplotDraw"
   ],
   "metadata": {
    "id": "jhSC_vBla1sW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1665907843396,
     "user_tz": 240,
     "elapsed": 2201,
     "user": {
      "displayName": "Enze Xu",
      "userId": "00384414745694091798"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "60561464-d469-4528-9b51-b7175ee28f0a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class Parameters:\n",
    "    N = 50\n",
    "    M = 50\n",
    "    d1 = 1\n",
    "    d2 = 40\n",
    "    c1 = 0.1  # 0.1\n",
    "    c2 = 0.9  # 0.9\n",
    "    c_1 = 1\n",
    "    c3 = 1\n",
    "    l = 1\n",
    "    w = 1\n",
    "\n",
    "class TrainArgs:\n",
    "    iteration = 1000000\n",
    "    epoch_step = 1\n",
    "    test_step = 10\n",
    "    initial_lr = 0.001\n",
    "    ignore_save_flag = True\n",
    "    main_path = \"/content/drive/My Drive/Workspace/Fourier_PINN/\"\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.model_name = \"Turing_Fourier\"\n",
    "        self.curve_names = [\"U\", \"V\"]\n",
    "        self.params = Parameters\n",
    "        self.args = TrainArgs\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.seed = 0\n",
    "\n",
    "        self.T_before = 30\n",
    "        self.noise_rate = 0.05\n",
    "        self.T = 2\n",
    "        self.T_unit = 2e-3\n",
    "        self.T_N_before = int(self.T_before / self.T_unit)\n",
    "        self.T_N = int(self.T / self.T_unit)\n",
    "\n",
    "        self.prob_dim = 2\n",
    "\n",
    "        torch.manual_seed(self.seed)\n",
    "        torch.cuda.manual_seed_all(self.seed)\n",
    "        self.y0_before = torch.rand([self.params.N, self.params.M, self.prob_dim]).to(self.device) + 2.0\n",
    "        self.t_before = np.asarray([i * self.T_unit for i in range(self.T_N_before)])\n",
    "        self.t = np.asarray([i * self.T_unit for i in range(self.T_N)])\n",
    "        self.t_torch = torch.tensor(self.t, dtype=torch.float32).to(self.device)\n",
    "        # self.x = torch.tensor(np.asarray([[[i * self.T_unit] * self.prob_dim for i in range(self.T_N)]]), dtype=torch.float32).to(self.device)\n",
    "        # self.x = torch.tensor(np.asarray([[[i * self.T_unit] * self.prob_dim for i in range(self.T_N)]]), dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # x_1 = torch.zeros(self.params.N, self.params.M, 2, self.T_N).to(self.device)\n",
    "\n",
    "        # x_0 = torch.tensor([1.0 / (self.params.N * self.params.M) * i for i in range(self.params.N * self.params.M)]).reshape(self.params.N, self.params.M).to(self.device)\n",
    "        # x_1 = x_0.repeat(1, self.T_N, 1, 1)\n",
    "        # x_1 = x_1.permute(2, 3, 0, 1)\n",
    "        # x_2 = torch.tensor([i * self.T_unit for i in range(self.T_N)]).to(self.device)\n",
    "        # x = x_1 + x_2\n",
    "        # x = x.permute(3, 0, 1, 2)\n",
    "        # self.x = x.reshape([1, self.T_N, self.params.N, self.params.M, 1])\n",
    "        x = torch.zeros([1, self.T_N, self.params.N, self.params.M, 1]).to(self.device)\n",
    "        self.x = FNO3d.get_grid(x.shape, x.device)\n",
    "        print(\"x shape:\", self.x.shape)\n",
    "        # self.truth = odeint(self.pend, self.y0, self.t)\n",
    "\n",
    "\n",
    "        truth_path = self.args.main_path + \"/saves/turing_truth.npy\"\n",
    "        if os.path.exists(truth_path) and not self.args.ignore_save_flag:\n",
    "            self.truth = torch.tensor(np.load(truth_path), dtype=torch.float32).to(self.device)\n",
    "            self.y0 = self.truth[0]\n",
    "            print(\"Truth exists. Loading...\")\n",
    "        else:\n",
    "            truth_before = torchdiffeq.odeint(self.pend, self.y0_before.cpu(), torch.tensor(self.t_before), method='euler').to(self.device)\n",
    "            noise = (torch.rand([self.params.N, self.params.M, self.prob_dim]).to(self.device) - 0.5) * self.noise_rate\n",
    "            self.y0 = torch.abs(truth_before[-1] * (1.0 + noise) + 0.2)\n",
    "            self.truth = torchdiffeq.odeint(self.pend, self.y0.cpu(), torch.tensor(self.t), method='euler').to(self.device)\n",
    "            np.save(truth_path, self.truth.cpu().detach().numpy())\n",
    "        # print(\"y0:\")\n",
    "        # self.draw_turing(self.y0)\n",
    "        # print(\"Truth:\")\n",
    "        print(\"Truth U: max={0:.6f} min={1:.6f}\".format(torch.max(self.truth[:, :, :, 0]).item(), torch.min(self.truth[:, :, :, 0]).item()))\n",
    "        print(\"Truth V: max={0:.6f} min={1:.6f}\".format(torch.max(self.truth[:, :, :, 1]).item(), torch.min(self.truth[:, :, :, 1]).item()))\n",
    "        # self.draw_turing(self.truth[-1])\n",
    "\n",
    "\n",
    "        # self.modes = 64  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        # self.width = 16\n",
    "        self.modes1 = 12#8\n",
    "        self.modes2 = 12\n",
    "        self.modes3 = 12\n",
    "        self.width = 32#20\n",
    "        # self.fc_map_dim = 128\n",
    "    \n",
    "    def pend(self, t, y):\n",
    "        shapes = y.shape\n",
    "        reaction_part = torch.zeros([shapes[0], shapes[1], 2])\n",
    "        reaction_part[:, :, 0] = self.params.c1 - self.params.c_1 * y[:, :, 0] + self.params.c3 * (y[:, :, 0] ** 2) * y[:, :, 1]\n",
    "        reaction_part[:, :, 1] = self.params.c2 - self.params.c3 * (y[:, :, 0] ** 2) * y[:, :, 1]\n",
    "\n",
    "        y_from_left = torch.roll(y, 1, 1)\n",
    "        y_from_left[:, :1] = y[:, :1]\n",
    "        y_from_right = torch.roll(y, -1, 1)\n",
    "        y_from_right[:, -1:] = y[:, -1:]\n",
    "\n",
    "        y_from_top = torch.roll(y, 1, 0)\n",
    "        y_from_top[:1, :] = y[:1, :]\n",
    "        y_from_bottom = torch.roll(y, -1, 0)\n",
    "        y_from_bottom[-1:, :] = y[-1:, :]\n",
    "\n",
    "        diffusion_part = torch.zeros([shapes[0], shapes[1], 2])\n",
    "        diffusion_part[:, :, 0] = self.params.d1 * (((y_from_left[:, :, 0] + y_from_right[:, :, 0] - y[:, :, 0] * 2) / (self.params.l ** 2)) + ((y_from_top[:, :, 0] + y_from_bottom[:, :, 0] - y[:, :, 0] * 2) / (self.params.w ** 2)))\n",
    "        diffusion_part[:, :, 1] = self.params.d2 * (((y_from_left[:, :, 1] + y_from_right[:, :, 1] - y[:, :, 1] * 2) / (self.params.l ** 2)) + ((y_from_top[:, :, 1] + y_from_bottom[:, :, 1] - y[:, :, 1] * 2) / (self.params.w ** 2)))\n",
    "        return reaction_part + diffusion_part\n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_turing(map):\n",
    "        # map: N * M * 2\n",
    "        u = map[:, :, 0].cpu().detach().numpy()\n",
    "        v = map[:, :, 1].cpu().detach().numpy()\n",
    "        fig = plt.figure(figsize=(14, 6))\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        im1 = ax1.imshow(u, cmap=plt.cm.jet, aspect='auto')\n",
    "        ax1.set_title(\"u\")\n",
    "        cb1 = plt.colorbar(im1, shrink=1)\n",
    "\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        im2 = ax2.imshow(v, cmap=plt.cm.jet, aspect='auto')\n",
    "        ax2.set_title(\"v\")\n",
    "        cb2 = plt.colorbar(im2, shrink=1)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ],
   "metadata": {
    "id": "s2is2bMHa4Xh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "HIGQlNY5Dk9m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4bF4Zehaym5"
   },
   "outputs": [],
   "source": [
    "class SpectralConv3d(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(SpectralConv3d, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.in_channels = self.config.width\n",
    "        self.out_channels = self.config.width\n",
    "        self.modes1 = self.config.modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = self.config.modes2\n",
    "        self.modes3 = self.config.modes3\n",
    "\n",
    "        self.scale = (1 / (self.in_channels * self.out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(self.in_channels, self.out_channels, self.config.modes1, self.config.modes2, self.config.modes3, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(self.in_channels, self.out_channels, self.config.modes1, self.config.modes2, self.config.modes3, dtype=torch.cfloat))\n",
    "        self.weights3 = nn.Parameter(self.scale * torch.rand(self.in_channels, self.out_channels, self.config.modes1, self.config.modes2, self.config.modes3, dtype=torch.cfloat))\n",
    "        self.weights4 = nn.Parameter(self.scale * torch.rand(self.in_channels, self.out_channels, self.config.modes1, self.config.modes2, self.config.modes3, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul3d(self, input, weights):\n",
    "        # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3,-2,-1])\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.config.modes1, :self.config.modes2, :self.config.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.config.modes1, :self.config.modes2, :self.config.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.config.modes1:, :self.config.modes2, :self.config.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.config.modes1:, :self.config.modes2, :self.config.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.config.modes1, -self.config.modes2:, :self.config.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.config.modes1, -self.config.modes2:, :self.config.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.config.modes1:, -self.config.modes2:, :self.config.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.config.modes1:, -self.config.modes2:, :self.config.modes3], self.weights4)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class FNO3d(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FNO3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n",
    "        input shape: (batchsize, x=64, y=64, t=40, c=13)\n",
    "        output: the solution of the next 40 timesteps\n",
    "        output shape: (batchsize, x=64, y=64, t=40, c=1)\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.modes1 = self.config.modes1\n",
    "        self.modes2 = self.config.modes2\n",
    "        self.modes3 = self.config.modes3\n",
    "        self.width = self.config.width\n",
    "        self.padding = 6 # pad the domain if input is non-periodic\n",
    "        self.fc0 = nn.Linear(3, self.width)\n",
    "        # input channel is 12: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n",
    "\n",
    "        self.conv0 = SpectralConv3d(self.config)\n",
    "        self.conv1 = SpectralConv3d(self.config)\n",
    "        self.conv2 = SpectralConv3d(self.config)\n",
    "        self.conv3 = SpectralConv3d(self.config)\n",
    "        self.w0 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.bn0 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn1 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn3 = torch.nn.BatchNorm3d(self.width)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # grid = self.get_grid(x.shape, x.device)\n",
    "        # x = grid\n",
    "\n",
    "        # x = torch.cat((x, grid), dim=-1)\n",
    "        # print(\"cp1\", x.shape)\n",
    "        x = self.fc0(x)\n",
    "        # print(\"cp2\", x.shape)\n",
    "        x = x.permute(0, 4, 1, 2, 3)\n",
    "        # print(\"cp3\", x.shape)\n",
    "        # x = F.pad(x, [0,self.padding]) # pad the domain if input is non-periodic\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        # print(\"cp4\", x1.shape)\n",
    "        x2 = self.w0(x)\n",
    "        # print(\"cp5\", x2.shape)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        # print(\"cp6\", x.shape)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "        # print(\"cp7\", x.shape)\n",
    "        # x = x[..., :-self.padding]\n",
    "        # print(\"cp8\", x.shape)\n",
    "        x = x.permute(0, 2, 3, 4, 1) # pad the domain if input is non-periodic\n",
    "        # print(\"cp9\", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        # print(\"cp10\", x.shape)\n",
    "        x = F.gelu(x)\n",
    "        # print(\"cp11\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        # print(\"cp12\", x.shape)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def get_grid(shape, device):\n",
    "        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n",
    "        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n",
    "        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n",
    "        return torch.cat((gridx, gridy, gridz), dim=-1).to(device)\n",
    "\n",
    "\n",
    "class FourierModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FourierModel, self).__init__()\n",
    "        self.time_string = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime(time.time()))\n",
    "        self.config = config\n",
    "        self.setup_seed(self.config.seed)\n",
    "\n",
    "        # self.f_model_u = FNO3d(config)\n",
    "        # self.f_model_v = FNO3d(config)\n",
    "        self.f_model = FNO3d(config)\n",
    "        \n",
    "        # self.fc0 = nn.Linear(self.config.prob_dim, self.config.width)  # input channel is 2: (a(x), x)\n",
    "\n",
    "        # self.conv0 = SpectralConv1d(self.config)\n",
    "        # self.conv1 = SpectralConv1d(self.config)\n",
    "        # self.conv2 = SpectralConv1d(self.config)\n",
    "        # self.conv3 = SpectralConv1d(self.config)\n",
    "        # self.w0 = nn.Conv1d(self.config.width, self.config.width, 1)\n",
    "        # self.w1 = nn.Conv1d(self.config.width, self.config.width, 1)\n",
    "        # self.w2 = nn.Conv1d(self.config.width, self.config.width, 1)\n",
    "        # self.w3 = nn.Conv1d(self.config.width, self.config.width, 1)\n",
    "\n",
    "        # self.fc1 = nn.Linear(self.config.width, self.config.fc_map_dim)\n",
    "        # self.fc2 = nn.Linear(self.config.fc_map_dim, self.config.prob_dim)\n",
    "\n",
    "        self.criterion = torch.nn.MSELoss().to(self.config.device)#self.criterion = torch.nn.MSELoss(\"sum\").to(self.config.device)\n",
    "\n",
    "        self.y_tmp = None\n",
    "        self.epoch_tmp = None\n",
    "        self.loss_record_tmp = None\n",
    "\n",
    "        self.figure_save_path_folder = \"{0}/figure/{1}_{2}/\".format(self.config.args.main_path, self.config.model_name, self.time_string)\n",
    "        if not os.path.exists(self.figure_save_path_folder):\n",
    "            os.makedirs(self.figure_save_path_folder)\n",
    "        self.default_colors = [\"red\", \"blue\", \"green\", \"orange\", \"cyan\", \"purple\", \"pink\", \"indigo\", \"brown\", \"grey\"]\n",
    "\n",
    "        print(\"using {}\".format(str(self.config.device)))\n",
    "        print(\"iteration = {}\".format(self.config.args.iteration))\n",
    "        print(\"epoch_step = {}\".format(self.config.args.epoch_step))\n",
    "        print(\"test_step = {}\".format(self.config.args.test_step))\n",
    "        print(\"model_name = {}\".format(self.config.model_name))\n",
    "        print(\"time_string = {}\".format(self.time_string))\n",
    "        self.truth_loss()\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def setup_seed(seed):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    def ode_gradient(self, y):\n",
    "        # y: 1 * T_N * N * M * 2 \n",
    "        y = y[0]\n",
    "        shapes = y.shape\n",
    "        reaction_part = torch.zeros([shapes[0], shapes[1], shapes[2], 2]).to(self.config.device)\n",
    "        reaction_part[:, :, :, 0] = self.config.params.c1 - self.config.params.c_1 * y[:, :, :, 0] + self.config.params.c3 * (y[:, :, :, 0] ** 2) * y[:, :, :, 1]\n",
    "        reaction_part[:, :, :, 1] = self.config.params.c2 - self.config.params.c3 * (y[:, :, :, 0] ** 2) * y[:, :, :, 1]\n",
    "\n",
    "        y_from_left = torch.roll(y, 1, 2)\n",
    "        y_from_left[:, :, :1] = y[:, :, :1]\n",
    "        y_from_right = torch.roll(y, -1, 2)\n",
    "        y_from_right[:, :, -1:] = y[:, :, -1:]\n",
    "\n",
    "        y_from_top = torch.roll(y, 1, 1)\n",
    "        y_from_top[:, :1, :] = y[:, :1, :]\n",
    "        y_from_bottom = torch.roll(y, -1, 1)\n",
    "        y_from_bottom[:, -1:, :] = y[:, -1:, :]\n",
    "\n",
    "        diffusion_part = torch.zeros([shapes[0], shapes[1], shapes[2], 2]).to(self.config.device)\n",
    "        diffusion_part[:, :, :, 0] = self.config.params.d1 * (((y_from_left[:, :, :, 0] + y_from_right[:, :, :, 0] - y[:, :, :, 0] * 2) / (self.config.params.l ** 2)) + ((y_from_top[:, :, :, 0] + y_from_bottom[:, :, :, 0] - y[:, :, :, 0] * 2) / (self.config.params.w ** 2)))\n",
    "        diffusion_part[:, :, :, 1] = self.config.params.d2 * (((y_from_left[:, :, :, 1] + y_from_right[:, :, :, 1] - y[:, :, :, 1] * 2) / (self.config.params.l ** 2)) + ((y_from_top[:, :, :, 1] + y_from_bottom[:, :, :, 1] - y[:, :, :, 1] * 2) / (self.config.params.w ** 2)))\n",
    "\n",
    "        y_t_theory = reaction_part + diffusion_part\n",
    "\n",
    "        y_t = torch.gradient(y, spacing=(self.config.t_torch,), dim=0)[0]\n",
    "\n",
    "        return y_t - y_t_theory\n",
    "\n",
    "    def loss(self, y):\n",
    "        y0_pred = y[0, 0]\n",
    "        y0_true = self.config.y0\n",
    "\n",
    "        ode_y = self.ode_gradient(y)\n",
    "        zeros_nD = torch.zeros([self.config.T_N, self.config.params.N, self.config.params.M, self.config.prob_dim]).to(self.config.device)\n",
    "\n",
    "        loss1 = 1 * self.criterion(y0_pred, y0_true)\n",
    "        loss2 = 1e-1 * self.criterion(ode_y, zeros_nD)\n",
    "        \n",
    "        loss3 = 1 * (self.criterion(torch.abs(y -0.1), y -0.1) + self.criterion(torch.abs(6.5-y), 6.5-y))\n",
    "        # loss4 = self.criterion(1e-3 / (y[0, :, :] ** 2 + 1e-10), zeros_nD)\n",
    "        # self.criterion(1e-3 / (ode_1 ** 2 + 1e-10), zeros_1D) + self.criterion(1e-3 / (ode_2 ** 2 + 1e-10), zeros_1D) + self.criterion(1e-3 / (ode_3 ** 2 + 1e-10), zeros_1D)\n",
    "        # loss5 = self.criterion(torch.abs(u_0 - v_0), u_0 - v_0)\n",
    "\n",
    "        loss = loss1 + loss2 + loss3\n",
    "        loss_list = [loss1, loss2, loss3]\n",
    "        return loss, loss_list\n",
    "    \n",
    "    def truth_loss(self):\n",
    "        y_truth = self.config.truth.reshape([1, self.config.T_N, self.config.params.N, self.config.params.M, self.config.prob_dim])\n",
    "        # print(\"y_truth max:\", torch.max(y_truth))\n",
    "        # print(\"y_truth min:\", torch.min(y_truth))\n",
    "        tl, tl_list = self.loss(y_truth)\n",
    "        loss_print_part = \" \".join([\"Loss_{0:d}:{1:.8f}\".format(i + 1, loss_part.item()) for i, loss_part in enumerate(tl_list)])\n",
    "        print(\"Ground truth has loss: Loss:{0:.8f} {1}\".format(tl.item(), loss_print_part))\n",
    "    \n",
    "\n",
    "    def train_model(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.config.args.initial_lr, weight_decay=0)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda e: 1 / (e / 1000 + 1))\n",
    "        self.train()\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_time_0 = start_time\n",
    "        loss_record = []\n",
    "        \n",
    "        for epoch in range(1, self.config.args.iteration + 1):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # u = self.f_model_u(self.config.x)\n",
    "            # v = self.f_model_v(self.config.x)\n",
    "            y = self.f_model(self.config.x)\n",
    "            # print(\"y shape:\", y.shape)\n",
    "            # print(\"v shape:\", v.shape)\n",
    "            # y = torch.concat([u, v], dim=-1)\n",
    "            loss, loss_list = self.loss(y)\n",
    "            loss_record.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if epoch % self.config.args.epoch_step == 0:\n",
    "                now_time = time.time()\n",
    "                loss_print_part = \" \".join([\"Loss_{0:d}:{1:.8f}\".format(i + 1, loss_part.item()) for i, loss_part in enumerate(loss_list)])\n",
    "                print(\"Epoch [{0:05d}/{1:05d}] Loss:{2:.8f} {3} Lr:{4:.8f} Time:{5:.6f}s ({6:.2f}min in total, {7:.2f}min remains)\".format(epoch, self.config.args.iteration, loss.item(), loss_print_part, optimizer.param_groups[0][\"lr\"], now_time - start_time, (now_time - start_time_0) / 60.0, (now_time - start_time_0) / 60.0 / epoch * (self.config.args.iteration - epoch)))\n",
    "                start_time = now_time\n",
    "\n",
    "                if epoch % self.config.args.test_step == 0:\n",
    "                    self.y_tmp = y\n",
    "                    self.epoch_tmp = epoch\n",
    "                    self.loss_record_tmp = loss_record\n",
    "                    self.test_model()\n",
    "    \n",
    "    def test_model(self):\n",
    "        u_draw_all = self.y_tmp[0,:,:,:,0].reshape(self.config.T_N, self.config.params.N * self.config.params.M).cpu().detach().numpy().swapaxes(0, 1)[[10*i for i in range(10)]]\n",
    "        u_draw_all_truth = self.config.truth[:,:,:,0].reshape(self.config.T_N, self.config.params.N * self.config.params.M).cpu().detach().numpy().swapaxes(0, 1)[[10*i for i in range(10)]]\n",
    "        v_draw_all = self.y_tmp[0,:,:,:,1].reshape(self.config.T_N, self.config.params.N * self.config.params.M).cpu().detach().numpy().swapaxes(0, 1)[[10*i for i in range(10)]]\n",
    "        v_draw_all_truth = self.config.truth[:,:,:,1].reshape(self.config.T_N, self.config.params.N * self.config.params.M).cpu().detach().numpy().swapaxes(0, 1)[[10*i for i in range(10)]]\n",
    "        x_draw = self.config.t\n",
    "        draw_n = len(u_draw_all)\n",
    "        save_path_2D = \"{}/{}_{}_epoch={}_2D.png\".format(self.figure_save_path_folder, self.config.model_name, self.time_string, self.epoch_tmp)\n",
    "\n",
    "        m = MultiSubplotDraw(row=1, col=2, fig_size=(16, 6), tight_layout_flag=True, show_flag=True, save_flag=True, save_path=save_path_2D)\n",
    "        m.add_subplot(\n",
    "            y_lists=np.concatenate([u_draw_all, u_draw_all_truth], axis=0),\n",
    "            x_list=x_draw,\n",
    "            color_list=[self.default_colors[0]] * draw_n + [self.default_colors[1]] * draw_n,\n",
    "            line_style_list=[\"solid\"] * draw_n + [\"dashed\"] * draw_n,\n",
    "            fig_title=\"{}_{}_U_epoch={}_2D\".format(self.config.model_name, self.time_string, self.epoch_tmp),\n",
    "            line_width=0.5)\n",
    "        m.add_subplot(\n",
    "            y_lists=np.concatenate([v_draw_all, v_draw_all_truth], axis=0),\n",
    "            x_list=x_draw,\n",
    "            color_list=[self.default_colors[0]] * draw_n + [self.default_colors[1]] * draw_n,\n",
    "            line_style_list=[\"solid\"] * draw_n + [\"dashed\"] * draw_n,\n",
    "            fig_title=\"{}_{}_V_epoch={}_2D\".format(self.config.model_name, self.time_string, self.epoch_tmp),\n",
    "            line_width=0.5,)\n",
    "        m.draw()\n",
    "\n",
    "        # draw_two_dimension(\n",
    "        #     y_lists=np.concatenate([u_draw_all, u_draw_all_truth], axis=0),\n",
    "        #     x_list=x_draw,\n",
    "        #     color_list=[self.default_colors[0]] * draw_n + [self.default_colors[1]] * draw_n,\n",
    "        #     line_style_list=[\"solid\"] * draw_n + [\"dashed\"] * draw_n,\n",
    "        #     fig_title=\"{}_{}_U_epoch={}_2D\".format(self.config.model_name, self.time_string, self.epoch_tmp),\n",
    "        #     fig_size=(8, 6),\n",
    "        #     line_width=0.5,\n",
    "        #     show_flag=True,\n",
    "        #     save_flag=True,\n",
    "        #     save_path=save_path_2D_u,\n",
    "        # )\n",
    "        # save_path_2D_v = \"{}/{}_v_{}_epoch={}_2D.png\".format(self.figure_save_path_folder, self.config.model_name, self.time_string, self.epoch_tmp)\n",
    "        # draw_two_dimension(\n",
    "        #     y_lists=np.concatenate([v_draw_all, v_draw_all_truth], axis=0),\n",
    "        #     x_list=x_draw,\n",
    "        #     color_list=[self.default_colors[0]] * draw_n + [self.default_colors[1]] * draw_n,\n",
    "        #     line_style_list=[\"solid\"] * draw_n + [\"dashed\"] * draw_n,\n",
    "        #     fig_title=\"{}_{}_V_epoch={}_2D\".format(self.config.model_name, self.time_string, self.epoch_tmp),\n",
    "        #     fig_size=(8, 6),\n",
    "        #     line_width=0.5,\n",
    "        #     show_flag=True,\n",
    "        #     save_flag=True,\n",
    "        #     save_path=save_path_2D_v,\n",
    "        # )\n",
    "        print(\"2D Figure is saved to {}\".format(save_path_2D))\n",
    "        # y_draw = self.y_tmp[0].cpu().detach().numpy().swapaxes(0, 1)\n",
    "        # x_draw = self.config.t\n",
    "        # y_draw_truth = self.config.truth.swapaxes(0, 1)\n",
    "        # save_path_2D = \"{}/{}_{}_epoch={}_2D.png\".format(self.figure_save_path_folder, self.config.model_name, self.time_string, self.epoch_tmp)\n",
    "        # save_path_3D = \"{}/{}_{}_epoch={}_3D.png\".format(self.figure_save_path_folder, self.config.model_name, self.time_string, self.epoch_tmp)\n",
    "        # draw_two_dimension(\n",
    "        #     y_lists=np.concatenate([y_draw, y_draw_truth], axis=0),\n",
    "        #     x_list=x_draw,\n",
    "        #     color_list=self.default_colors[: 2 * self.config.prob_dim],\n",
    "        #     legend_list=self.config.curve_names + [\"{}_true\".format(item) for item in self.config.curve_names],\n",
    "        #     line_style_list=[\"solid\"] * self.config.prob_dim + [\"dashed\"] * self.config.prob_dim,\n",
    "        #     fig_title=\"{}_{}_epoch={}_2D\".format(self.config.model_name, self.time_string, self.epoch_tmp),\n",
    "        #     fig_size=(8, 6),\n",
    "        #     show_flag=True,\n",
    "        #     save_flag=True,\n",
    "        #     save_path=save_path_2D,\n",
    "        # )\n",
    "        # print(\"2D Figure is saved to {}\".format(save_path_2D))\n",
    "\n",
    "        # draw_three_dimension(\n",
    "        #     lists=[y_draw, y_draw_truth],\n",
    "        #     legend_list=[\"pred\", \"true\"],\n",
    "        #     color_list=self.default_colors[:2],\n",
    "        #     line_style_list=[\"solid\", \"dashed\"],\n",
    "        #     fig_title=\"{}_{}_epoch={}_3D\".format(self.config.model_name, self.time_string, self.epoch_tmp),\n",
    "        #     alpha=0.7,\n",
    "        #     show_flag=True,\n",
    "        #     save_flag=True,\n",
    "        #     save_path=save_path_3D,\n",
    "        #     fig_size=(8, 6),\n",
    "        #     line_width=1.0,\n",
    "        #     lim_adaptive_flag=True\n",
    "        # )\n",
    "        # print(\"3D Figure is saved to {}\".format(save_path_3D))\n",
    "\n",
    "        # y_draw = self.y_tmp[0, -1]\n",
    "        # y_draw_truth = self.config.truth[-1]\n",
    "        # print(\"Pred: {}\".format(y_draw.shape))\n",
    "        # self.config.draw_turing(y_draw)\n",
    "        # print(\"True: {}\".format(y_draw_truth.shape))\n",
    "        # self.config.draw_turing(y_draw_truth)\n",
    "        u = self.y_tmp[0, :, :, :, 0].cpu().detach().numpy()\n",
    "        v = self.y_tmp[0, :, :, :, 1].cpu().detach().numpy()\n",
    "        u_last = u[-1]\n",
    "        v_last = v[-1]\n",
    "        u_true = self.config.truth[:, :, :, 0].cpu().detach().numpy()\n",
    "        v_true = self.config.truth[:, :, :, 1].cpu().detach().numpy()\n",
    "        u_last_true = u_true[-1]\n",
    "        v_last_true = v_true[-1]\n",
    "        save_path_map_all = \"{}/{}_{}_epoch={}_map_all.png\".format(self.figure_save_path_folder, self.config.model_name, self.time_string, self.epoch_tmp)\n",
    "        save_path_map_pred_only = \"{}/{}_{}_epoch={}_map_pred_only.png\".format(self.figure_save_path_folder, self.config.model_name, self.time_string, self.epoch_tmp)\n",
    "        m = MultiSubplotDraw(row=2, col=2, fig_size=(16, 14), tight_layout_flag=True, save_flag=True, save_path=save_path_map_all)\n",
    "        m.add_subplot_turing(\n",
    "            matrix=u_last,\n",
    "            v_max=u_last_true.max(),\n",
    "            v_min=u_last_true.min(),\n",
    "            fig_title_size=10,\n",
    "            number_label_size=10,\n",
    "            fig_title=\"{}_{}_U_pred_epoch={}\".format(self.config.model_name, self.time_string, self.epoch_tmp))\n",
    "        m.add_subplot_turing(\n",
    "            matrix=v_last,\n",
    "            v_max=v_last_true.max(),\n",
    "            v_min=v_last_true.min(),\n",
    "            fig_title_size=10,\n",
    "            number_label_size=10,\n",
    "            fig_title=\"{}_{}_V_pred_epoch={}\".format(self.config.model_name, self.time_string, self.epoch_tmp))\n",
    "        m.add_subplot_turing(\n",
    "            matrix=u_last_true,\n",
    "            v_max=u_last_true.max(),\n",
    "            v_min=u_last_true.min(),\n",
    "            fig_title_size=10,\n",
    "            number_label_size=10,\n",
    "            fig_title=\"{}_{}_U_true\".format(self.config.model_name, self.time_string))\n",
    "        m.add_subplot_turing(\n",
    "            matrix=v_last_true,\n",
    "            v_max=v_last_true.max(),\n",
    "            v_min=v_last_true.min(),\n",
    "            fig_title_size=10,\n",
    "            number_label_size=10,\n",
    "            fig_title=\"{}_{}_V_true\".format(self.config.model_name, self.time_string))\n",
    "        m.draw()\n",
    "\n",
    "        m = MultiSubplotDraw(row=1, col=2, fig_size=(16, 7), tight_layout_flag=True, show_flag=False, save_flag=True, save_path=save_path_map_pred_only)\n",
    "        m.add_subplot_turing(\n",
    "            matrix=u_last,\n",
    "            v_max=u_last_true.max(),\n",
    "            v_min=u_last_true.min(),\n",
    "            fig_title_size=10,\n",
    "            number_label_size=10,\n",
    "            fig_title=\"{}_{}_U_pred_epoch={}\".format(self.config.model_name, self.time_string, self.epoch_tmp))\n",
    "        m.add_subplot_turing(\n",
    "            matrix=v_last,\n",
    "            v_max=v_last_true.max(),\n",
    "            v_min=v_last_true.min(),\n",
    "            fig_title_size=10,\n",
    "            number_label_size=10,\n",
    "            fig_title=\"{}_{}_V_pred_epoch={}\".format(self.config.model_name, self.time_string, self.epoch_tmp))\n",
    "        m.draw()\n",
    "\n",
    "        self.draw_loss_multi(self.loss_record_tmp, [1.0, 0.5, 0.25, 0.125])\n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_loss_multi(loss_list, last_rate_list):\n",
    "        m = MultiSubplotDraw(row=1, col=len(last_rate_list), fig_size=(8 * len(last_rate_list), 6), tight_layout_flag=True, show_flag=True, save_flag=False, save_path=None)\n",
    "        for one_rate in last_rate_list:\n",
    "            m.add_subplot(\n",
    "                y_lists=[loss_list[-int(len(loss_list) * one_rate):]],\n",
    "                x_list=range(len(loss_list) - int(len(loss_list) * one_rate) + 1, len(loss_list) + 1),\n",
    "                color_list=[\"blue\"],\n",
    "                line_style_list=[\"solid\"],\n",
    "                fig_title=\"Loss - lastest ${}$% - epoch ${}$ to ${}$\".format(int(100 * one_rate), len(loss_list) - int(len(loss_list) * one_rate) + 1, len(loss_list)),\n",
    "                fig_x_label=\"epoch\",\n",
    "                fig_y_label=\"loss\",\n",
    "            )\n",
    "        m.draw()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config = Config()\n",
    "model = FourierModel(config).to(config.device)\n",
    "model.train_model()"
   ],
   "metadata": {
    "id": "qgJViunqGEHx"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}